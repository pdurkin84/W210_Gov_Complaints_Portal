{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.20.0.\n"
     ]
    }
   ],
   "source": [
    "from finetune import Classifier, config\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82484, 5)\n",
      "service_name                                                 Yard Waste\n",
      "description           Neighbor water buckets\\n\\nThe owner of the hou...\n",
      "agency_responsible                                                  NaN\n",
      "OurLabel                                                     Yard Waste\n",
      "OurNumericLabel                                                       8\n",
      "Name: 82480, dtype: object\n"
     ]
    }
   ],
   "source": [
    "filePath = \"Processing_eda/Bloomington_311_processed_3.csv\"\n",
    "data3 = pandas.read_csv(filePath)\n",
    "print(data3.shape)\n",
    "print(data3.loc[82480])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter data only to ones with at least 40 characters and at most 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41374, 5)\n"
     ]
    }
   ],
   "source": [
    "mask = (data3['description'].str.len() >=40) & (data3['description'].str.len() <=512)\n",
    "dataFiltered = data3.loc[mask]\n",
    "print(dataFiltered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for columns with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agency_responsible']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFiltered.columns[dataFiltered.isna().any()].tolist()\n",
    "# ourLabel doesn't have NaN values, so that is good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(41374, 2)\n",
      "(33099,)\n",
      "<class 'pandas.core.series.Series'>\n",
      "(33099,)\n"
     ]
    }
   ],
   "source": [
    "trainingData = dataFiltered[[\"description\", \"OurLabel\"]]\n",
    "print(type(trainingData))\n",
    "print(trainingData.shape)\n",
    "trainX, testX, trainY, testY = train_test_split(trainingData.description, trainingData.OurLabel, test_size=0.2, random_state=42)\n",
    "# bigMask = (trainingData[\"description\"].str.len() >=1000)\n",
    "# print(trainingData.loc[bigMask].shape)\n",
    "# Split in train and test 80/20\n",
    "print(trainX.shape)\n",
    "print(type(trainX))\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a model with finetune (this part fails because of CPU overload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier(max_length=512, val_interval=3000, verbose = False)               # Load base model\n",
    "model.fit(trainX, trainY)          # Finetune base model on custom data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test) # [{'class_1': 0.23, 'class_2': 0.54, ..}, ..]\n",
    "model.save(\"newModel\")                   # Serialize the model to disk\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
