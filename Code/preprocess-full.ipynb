{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "from finetune import Classifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import re, string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1278129, 10)\n",
      "index                                                             0\n",
      "COMPLAINT_ID                                        US_CHICAGO_1725\n",
      "CITY                                                     US_CHICAGO\n",
      "COMPLAINT DATE                                           10/03/2011\n",
      "DEPT_311                                         health_environment\n",
      "CODE_311                           permits issued by doe work order\n",
      "CATEGORY_MAIN                                           environment\n",
      "CATEGORY_SUB                                    environment_general\n",
      "COMPLAINT_1       QUESTIONABLE BUSINESS PRACTICES REGARDING OILS...\n",
      "COMPLAINT_2       [INSPECTION LOG #: 1723 03-OCT-11 18:55:00] TH...\n",
      "Name: 0, dtype: object\n",
      "['COMPLAINT DATE', 'DEPT_311', 'COMPLAINT_1', 'COMPLAINT_2']\n",
      "(14025, 10)\n",
      "(964291, 10)\n",
      "(13579, 10)\n",
      "(0, 10)\n",
      "(0, 10)\n",
      "(0, 10)\n",
      "(0,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:119: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing exclusion phrases- autogenerted text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping complaints less than 4 chars long\n",
      "(964228, 11)\n",
      "removing complaints that simply state: <<new >> \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(960376, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data=pd.read_csv(\\\n",
    "                     'https://s3.amazonaws.com/danicic-w210/combined_trainingdata_20181013.tsv',sep='\\t')\n",
    "\n",
    "print(data.shape)\n",
    "print(data.loc[0])\n",
    "\n",
    "print(data.columns[data.isna().any()].tolist())\n",
    "print(data[data.COMPLAINT_1.isna()].shape)\n",
    "print(data[data.COMPLAINT_2.isna()].shape)\n",
    "print(data[(data.COMPLAINT_1.isna()) & (data.COMPLAINT_2.isna())].shape)\n",
    "\n",
    "dataFiltered = data.dropna(subset = [\"COMPLAINT_1\"])\n",
    "print(dataFiltered[(dataFiltered.COMPLAINT_1.isna())].shape)\n",
    "print(dataFiltered[(dataFiltered.COMPLAINT_1.isna()) & (dataFiltered.COMPLAINT_2.isna())].shape)\n",
    "print(dataFiltered[dataFiltered.COMPLAINT_1 == \"\"].shape)\n",
    "\n",
    "\n",
    "# Alex's\n",
    "def clean_specifics(complaint):\n",
    "    complaint = re.sub('Request entered through the Web. Refer to Intake Questions for further description.',\n",
    "                      '', complaint)\n",
    "    complaint = re.sub('Transfer:.+/[A-Z]+', '', complaint)\n",
    "    complaint = re.sub('ACCT ', '', complaint)\n",
    "    complaint = re.sub('RTC ', '', complaint)\n",
    "    return complaint\n",
    "  \n",
    "  \n",
    " # Preprocess `merged_complaint`\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "\n",
    "# eliminate stop phrases\n",
    "# remove rows where complaint len <4\n",
    "\n",
    "stop_phrases=['request entered web refer intake questions description',\\\n",
    "             'duplicate',\\\n",
    "             'batch created',\\\n",
    "             'issue reported city oakland public works department via phone email pwacallcenteroaklandnetcom web wwwoaklandpwcom',\\\n",
    "             'issue reported city oakland call center via phone email callcenteroaklandnetcom web wwwoaklandpwcom',\\\n",
    "             'issue reported city oakland public works agency via phone email pwacallcenteroaklandnetcom web wwwoaklandpwcom',\\\n",
    "             'issue reported oak via phone outside oakland email oakoaklandnetcom web oaklandcagov',\\\n",
    "             'request entered web refer intake questions description',\\\n",
    "             'waze user reported',\\\n",
    "             'council member smitherman reporting',\\\n",
    "             'issue reported city ann arbor customer service via phone email customerserviceagovorg web wwwagovorg',\\\n",
    "             'test report',\\\n",
    "             'reported mobile device httpmseeclickfixcom',\\\n",
    "             'information may available cdph environmental inspections dataset',\\\n",
    "             'ftc',\\\n",
    "             'resident reports',\\\n",
    "             'reported'\\\n",
    "             'rtc',\\\n",
    "             'acct',\\\n",
    "             'batch group'\\\n",
    "             'mt airy nep']\n",
    "\n",
    "\n",
    "# eliminate entire row of these complaints\n",
    "\n",
    "elim_list=['this issue was reported to the city of oakland public works agency via phone nnnnnnnnnn email pwacallcenteroaklandnetcom or web wwwoaklandpwcom',\\\n",
    "          'bu',\\\n",
    "          'rtc',\\\n",
    "          'mt airy nep nnnn',\\\n",
    "          'batch group nn',\\\n",
    "          'this issue was reported to oak nnn via phone nnn or nnnnnnnnnn from outside oakland email oaknnnoaklandnetcom or web nnnoaklandcagov',\\\n",
    "          'waze user reported',\\\n",
    "          'this issue was reported to the city of ann arbor customer service via phone nnn nnnnnnn email customerserviceangovorg or web wwwangovorg',\\\n",
    "          'reported by nn',\\\n",
    "          'council member smitherman reporting',\\\n",
    "          'nnn reported ps nnn down',\\\n",
    "          'test report',\\\n",
    "          'p c g s b',\\\n",
    "          'junkyard issues more information may be available in the cdph environmental inspections dataset',\\\n",
    "          'reissue ccnnnnnnnn to update']\n",
    "\n",
    "# Stan's + Alex\n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation) # To remove punctuation\n",
    "\n",
    "def preProcess(complaintStart):\n",
    "    complaint = clean_specifics(complaintStart)\n",
    "    complaint = ' '.join([word for word in complaint.split() if word not in cachedStopWords]) # remove stopwords (alex) early on to make 512 limit \n",
    "    complaint = complaintStart[:512] # cut to 512 characters max\n",
    "    complaint = re.sub(\"\\d\",\"\", complaint) # remove numbers completely (alex)\n",
    "    complaint = complaint.lower().translate(translator) # lower case and remove the punctuation\n",
    "    complaint = re.sub('[^\\w\\s]', ' ', complaint) # Sub puncuation with space (alex)\n",
    "    complaint = complaint.strip() # (alex)\n",
    "    complaint = re.sub(' +', ' ', complaint) # Remove dupe spaces (alex)\n",
    "    complaint = complaint.replace(\"\\n\",\" \").strip() # remove starting and trailing white spaces\n",
    "    if re.search('[a-zA-Z]', complaint) is None:# if there are no letters in the complaint, return empty, will be removed in later processing\n",
    "        return \"\"\n",
    "    complaint = ' '.join([word for word in complaint.split() if word not in cachedStopWords]) # remove stopwords at end after preprocessing (alex) \n",
    "    return complaint\n",
    "\n",
    "def getComplaint(row):\n",
    "    complaint2 = row.get(\"COMPLAINT_2\")\n",
    "    if not pd.isnull(complaint2):\n",
    "        if \"[INSPECTION LOG #:\" in complaint2: # Remove inspection log section from C2\n",
    "            complaintStrippedList = complaint2.split(\"]\")[1:]\n",
    "            complaintFinal = \"]\".join(complaintStrippedList)\n",
    "        else:\n",
    "            complaintFinal = complaint2\n",
    "        if row.get(\"CITY\")==\"US_CHICAGO\": # if Chicago, concatenate the two\n",
    "            complaintFinal = row.get(\"COMPLAINT_1\") + \" \"+ complaintFinal\n",
    "        complaintProcessed = preProcess(complaintFinal)\n",
    "        if complaintProcessed == \"\" or re.search('[a-zA-Z]', complaintProcessed) is None: # if nothing or no letters\n",
    "            return preProcess(row.get(\"COMPLAINT_1\"))\n",
    "        return complaintProcessed\n",
    "    complaintProcessed = preProcess(row.get(\"COMPLAINT_1\"))\n",
    "    return complaintProcessed\n",
    "\n",
    "results = dataFiltered.apply(lambda row: getComplaint (row),axis=1)\n",
    "print(results[results.isna()].shape)\n",
    "\n",
    "dataFiltered[\"complaint\"] = results\n",
    "print(dataFiltered[dataFiltered.complaint.isna()].shape)\n",
    "\n",
    "dataFiltered[\"CATEGORY_SUB\"] = dataFiltered[\"CATEGORY_SUB\"].str.strip()\n",
    "\n",
    "# eliminate stop_phrases\n",
    "print('removing exclusion phrases- autogenerted text')\n",
    "exclusions = '|'.join(stop_phrases)  #first_word = re.sub(exclusions, '', first_word)\n",
    "dataFiltered['complaint']=dataFiltered['complaint'].map(lambda x: re.sub(exclusions,'',x))\n",
    "\n",
    "# strip leading and trailing spaces\n",
    "dataFiltered['complaint'] = dataFiltered['complaint'].str.strip()\n",
    "\n",
    "# keep only len 4 and greater\n",
    "print('dropping complaints less than 4 chars long')\n",
    "dataFiltered = dataFiltered.loc[(dataFiltered[\"complaint\"].str.len() >=4)]\n",
    "print(dataFiltered.shape)\n",
    "\n",
    "stop_complaints=['reported',\\\n",
    "                'reported ps',\\\n",
    "                #'locked',\\  # one word locked doesn't say much, but all related to unsafe planning, so dont want to miss locked [door, fire escape, etc] with pic\n",
    "                'batch group',\\\n",
    "                'mt airy nep']\n",
    "\n",
    "dataFiltered=dataFiltered[~dataFiltered['complaint'].isin(stop_complaints)]\n",
    "print('removing complaints that simply state: <<new >> ')\n",
    "dataFiltered.drop(dataFiltered.loc[dataFiltered['complaint']=='new '].index, inplace=True)\n",
    "dataFiltered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960376, 11)\n",
      "(958234, 11)\n",
      "Removed labels with too few samples\n"
     ]
    }
   ],
   "source": [
    "# extract only classes for which we have more than 500 complaints\n",
    "aggregation = {\"complaint\":\"count\"}\n",
    "aggregatedByLabel = dataFiltered.groupby(\"CATEGORY_SUB\").agg(aggregation)\n",
    "\n",
    "goodLabels = aggregatedByLabel[aggregatedByLabel[\"complaint\"]>500]\n",
    "goodLabelsList = goodLabels.index.tolist()\n",
    "print(dataFiltered.shape)\n",
    "dataFiltered = dataFiltered[dataFiltered[\"CATEGORY_SUB\"].isin(goodLabelsList)]\n",
    "print(dataFiltered.shape)\n",
    "print(\"Removed labels with too few samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated Mapping from SUB to MAIN category\n",
      "{'street_urgent_repair': 'street', 'infrastructure_power': 'infrastructure', 'street_repair': 'street', 'publichealth_general': 'public_health', 'environment_recycling': 'environment', 'housing_mold': 'housing', 'environment_garbage_collection': 'environment', 'environment_overgrowth': 'environment', 'street_lighting': 'street', 'street_sewar': 'street', 'environment_dead_animal': 'environment', 'street_slippery': 'street', 'housing_general': 'housing', 'infrastructure_water_repair': 'infrastructure', 'governance_signage': 'governance', 'street_sidewalk': 'street', 'street_parking': 'street', 'housing_safety': 'housing', 'fire_general': 'fire', 'environment_air_pollution': 'environment', 'street_drainage': 'street', 'publichealth_animal': 'public_health', 'fire_equipment_broken': 'fire', 'governance_general': 'governance', 'housing_health_code': 'housing', 'publichealth_restaurant_hygiene': 'public_health', 'environment_dumping': 'environment', 'publicorder_noise_complaint': 'public_order', 'environment_asbestos': 'environment', 'planning_unsafe_environment': 'planning', 'environment_litter': 'environment', 'vandalism_graffiti': 'vandalism', 'infrastructure_water': 'infrastructure', 'governance_parks_and_rec': 'governance', 'environment_abandoned_site': 'environment', 'environment_general': 'environment', 'publicorder_general': 'public_order', 'publichealth_animal_feces': 'public_health', 'street_cleaning': 'street', 'environment_abandoned_vehicle': 'environment', 'publichealth_pests': 'public_health', 'planning_general': 'planning', 'street_general': 'street', 'infrastructure_general': 'infrastructure', 'environment_hazardous_material': 'environment'}\n"
     ]
    }
   ],
   "source": [
    "# get mapping from sub to main category\n",
    "labelsMap = dataFiltered[[\"CATEGORY_MAIN\", \"CATEGORY_SUB\"]].drop_duplicates()\n",
    "labelsMap = labelsMap.set_index(\"CATEGORY_SUB\").to_dict()[\"CATEGORY_MAIN\"]\n",
    "print(\"Calculated Mapping from SUB to MAIN category\")\n",
    "print(labelsMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only columns we care about\n",
    "dataFiltered = dataFiltered[[\"complaint\", \"CATEGORY_SUB\", \"CATEGORY_MAIN\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write result to tsv\n",
    "dataFiltered.to_csv(\"/W210_Gov_Complaints_Portal/Datasets/combined_trainingdata_filtered_20181108.tsv\", sep='\\t' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
